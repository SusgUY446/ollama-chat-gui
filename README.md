# Ollama Chat GUI

A gui for ollama. 

Default model: llama2-uncensored


## How to run
```
pip install -r requirements.txt
python main.py
```


(you need to run a ollama server first. download ollama at https://ollama.com then run 'ollama run <your-preferd-model>')



## Configuring
just read the `config.txt`. Its self explaning




